"""
æ•°æ®å¯è§†åŒ–ä¸æœºå™¨å­¦ä¹ é¢„æµ‹åˆ†æå·¥å…·
ç®€åŒ–ç‰ˆ - æ‰€æœ‰åŠŸèƒ½æ•´åˆåˆ°ä¸€ä¸ªæ–‡ä»¶
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.svm import SVR, SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, 
                            classification_report, f1_score, precision_score, 
                            recall_score, roc_auc_score, mean_absolute_error,
                            confusion_matrix, roc_curve, auc)
from typing import Optional, List, Dict, Any, Union
import warnings
warnings.filterwarnings('ignore')

# å°è¯•å¯¼å…¥XGBoostï¼ˆå¯é€‰ï¼‰
XGBRegressor = None
XGBClassifier = None
try:
    from xgboost import XGBRegressor, XGBClassifier
    print("æˆåŠŸå¯¼å…¥XGBoost")
except ImportError:
    print("XGBoostæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ï¼Œå°†ä¸ä½¿ç”¨XGBoostæ¨¡å‹")
    XGBRegressor = None
    XGBClassifier = None

# ä¸åœ¨é¡¶å±‚å¯¼å…¥LightGBMï¼Œè€Œæ˜¯åœ¨éœ€è¦æ—¶å¯¼å…¥
# LightGBMä¼šåœ¨get_regression_modelså’Œget_classification_modelså‡½æ•°ä¸­å°è¯•å¯¼å…¥

# åº”ç”¨é…ç½®
APP_CONFIG = {
    'page_title': 'æ•°æ®å¯è§†åŒ–ä¸æœºå™¨å­¦ä¹ é¢„æµ‹åˆ†æ',
    'page_icon': 'ğŸ“Š',
    'layout': "wide",  # ä½¿ç”¨å­—é¢é‡è€Œéå˜é‡
    'initial_sidebar_state': "expanded"  # ä½¿ç”¨å­—é¢é‡è€Œéå˜é‡
}

# é»˜è®¤è·¯å¾„é…ç½®
DEFAULT_PATHS = {
    'data_directory': r"D:\code_study\ML_CODE\kaggle\Regression\Red Wine Quality"
}

# ========== å·¥å…·å‡½æ•° ==========
def is_valid_directory(directory_path: str) -> bool:
    """æ£€æŸ¥ç›®å½•æ˜¯å¦æœ‰æ•ˆ"""
    return os.path.isdir(directory_path)

def get_csv_files(directory_path: str) -> List[str]:
    """è·å–ç›®å½•ä¸­çš„CSVæ–‡ä»¶åˆ—è¡¨"""
    if not is_valid_directory(directory_path):
        return []
    
    try:
        file_list = [f for f in os.listdir(directory_path) if f.endswith('.csv')]
        return file_list
    except Exception as e:
        st.error(f"è¯»å–ç›®å½•æ—¶å‡ºé”™: {e}")
        return []

def load_data(directory_path: str, file_name: str) -> Optional[pd.DataFrame]:
    """åŠ è½½CSVæ•°æ®æ–‡ä»¶"""
    try:
        file_path = os.path.join(directory_path, file_name)
        df = pd.read_csv(file_path)
        return df
    except Exception as e:
        st.error(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

def remove_outliers(df, cols, method='3sigma'):
    """ç§»é™¤å¼‚å¸¸å€¼"""
    df_clean = df.copy()
    if method == '3sigma':
        for col in cols:
            if df_clean[col].dtype in [np.float64, np.int64]:
                mean = df_clean[col].mean()
                std = df_clean[col].std()
                df_clean = df_clean[(df_clean[col] >= mean - 3*std) & (df_clean[col] <= mean + 3*std)]
    elif method == 'iqr':
        for col in cols:
            if df_clean[col].dtype in [np.float64, np.int64]:
                Q1 = df_clean[col].quantile(0.25)
                Q3 = df_clean[col].quantile(0.75)
                IQR = Q3 - Q1
                df_clean = df_clean[(df_clean[col] >= Q1 - 1.5*IQR) & (df_clean[col] <= Q3 + 1.5*IQR)]
    return df_clean

# ========== æ•°æ®å¯è§†åŒ–æ¨¡å— ==========
def render_visualization(df):
    """æ¸²æŸ“å¯è§†åŒ–ç•Œé¢"""
    st.write("æ•°æ®é¢„è§ˆï¼š")
    # è¡¨æ ¼ç¾åŒ–
    st.dataframe(df, use_container_width=True)

    st.write("æ•°æ®æè¿°ï¼š")
    st.dataframe(df.describe(), use_container_width=True)

    numeric_cols = df.select_dtypes(include='number').columns.tolist()
    if len(numeric_cols) > 0:
        # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„åˆ—
        default_cols = st.session_state.get('viz_selected_cols', numeric_cols[:1] if numeric_cols else [])
        selected_cols = st.multiselect(
            "é€‰æ‹©è¦å¯è§†åŒ–çš„æ•°å€¼åˆ—ï¼ˆå¯å¤šé€‰ï¼‰", 
            numeric_cols, 
            default=default_cols
        )
        # ä¿å­˜é€‰æ‹©åˆ°session_state
        st.session_state['viz_selected_cols'] = selected_cols
        
        # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„å›¾è¡¨ç±»å‹
        default_chart_type = st.session_state.get('viz_chart_type', "æŠ˜çº¿å›¾")
        chart_type = st.selectbox("é€‰æ‹©å›¾è¡¨ç±»å‹", ["æŠ˜çº¿å›¾", "ç®±çº¿å›¾", "ç›´æ–¹å›¾", "ç›¸å…³æ€§çƒ­åŠ›å›¾"], 
                                 index=["æŠ˜çº¿å›¾", "ç®±çº¿å›¾", "ç›´æ–¹å›¾", "ç›¸å…³æ€§çƒ­åŠ›å›¾"].index(default_chart_type))
        # ä¿å­˜é€‰æ‹©åˆ°session_state
        st.session_state['viz_chart_type'] = chart_type
        
        if selected_cols:
            create_chart(df, selected_cols, chart_type)
        else:
            st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ•°å€¼åˆ—è¿›è¡Œå¯è§†åŒ–ã€‚")
    else:
        st.warning("æ•°æ®ä¸­æ²¡æœ‰æ•°å€¼åˆ—ï¼")

def create_chart(df, selected_cols, chart_type):
    """åˆ›å»ºæŒ‡å®šç±»å‹çš„å›¾è¡¨"""
    if chart_type == "æŠ˜çº¿å›¾":
        fig = px.line(df, y=selected_cols, title="æŠ˜çº¿å›¾", markers=True)
        fig.update_layout(xaxis_title="ç´¢å¼•", yaxis_title=", ".join(selected_cols))
        st.plotly_chart(fig, use_container_width=True)
    
    elif chart_type == "ç®±çº¿å›¾":
        if len(selected_cols) == 1:
            fig = px.box(df, y=selected_cols[0], title="ç®±çº¿å›¾")
        else:
            df_melt = df[selected_cols].melt(var_name="ç‰¹å¾", value_name="å€¼")
            fig = px.box(df_melt, x="ç‰¹å¾", y="å€¼", title="ç®±çº¿å›¾")
        st.plotly_chart(fig, use_container_width=True)
    
    elif chart_type == "ç›´æ–¹å›¾":
        if len(selected_cols) > 1:
            fig = go.Figure()
            for col in selected_cols:
                fig.add_trace(go.Histogram(
                    x=df[col],
                    name=col,
                    opacity=0.7,
                    nbinsx=30
                ))
            fig.update_layout(
                title="å¤šç‰¹å¾ç›´æ–¹å›¾æ¯”è¾ƒ",
                barmode='overlay',
                xaxis_title="å€¼",
                yaxis_title="é¢‘æ¬¡"
            )
        else:
            fig = px.histogram(
                df, 
                x=selected_cols[0], 
                title="ç›´æ–¹å›¾",
                marginal="box",
                nbins=30
            )
        st.plotly_chart(fig, use_container_width=True)
    
    elif chart_type == "ç›¸å…³æ€§çƒ­åŠ›å›¾":
        corr_matrix = pd.DataFrame(df[selected_cols]).corr()
        fig = px.imshow(corr_matrix, text_auto=True, aspect="auto", title="ç›¸å…³æ€§çƒ­åŠ›å›¾")
        st.plotly_chart(fig, use_container_width=True)

# ========== ç‰¹å¾å·¥ç¨‹æ¨¡å— ==========
def render_feature_engineering(df):
    """æ¸²æŸ“ç‰¹å¾å·¥ç¨‹ç•Œé¢"""
    st.header("ç‰¹å¾å·¥ç¨‹")
    
    # æ•°æ®é¢„å¤„ç†
    st.subheader("1. æ•°æ®é¢„å¤„ç†")
    missing_data = df.isnull().sum()
    if missing_data.sum() > 0:
        st.write("ç¼ºå¤±å€¼ç»Ÿè®¡ï¼š")
        st.write(missing_data[missing_data > 0])
        
        # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥
        default_missing_strategy = st.session_state.get('missing_strategy', "åˆ é™¤è¡Œ")
        missing_strategy = st.selectbox(
            "é€‰æ‹©ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥", 
            ["åˆ é™¤è¡Œ", "å‡å€¼å¡«å……", "ä¸­ä½æ•°å¡«å……", "ä¼—æ•°å¡«å……"],
            index=["åˆ é™¤è¡Œ", "å‡å€¼å¡«å……", "ä¸­ä½æ•°å¡«å……", "ä¼—æ•°å¡«å……"].index(default_missing_strategy)
        )
        # ä¿å­˜é€‰æ‹©åˆ°session_state
        st.session_state['missing_strategy'] = missing_strategy
        
        if missing_strategy == "åˆ é™¤è¡Œ":
            df_clean = df.dropna()
        elif missing_strategy == "å‡å€¼å¡«å……":
            df_clean = df.fillna(df.mean())
        elif missing_strategy == "ä¸­ä½æ•°å¡«å……":
            df_clean = df.fillna(df.median())
        elif missing_strategy == "ä¼—æ•°å¡«å……":
            df_clean = df.fillna(df.mode().iloc[0])
    else:
        df_clean = df.copy()
        st.success("æ•°æ®ä¸­æ²¡æœ‰ç¼ºå¤±å€¼ï¼")
    
    # å¼‚å¸¸å€¼å¤„ç†
    st.subheader("2. å¼‚å¸¸å€¼å¤„ç†")
    numeric_cols = df_clean.select_dtypes(include='number').columns.tolist()
    if len(numeric_cols) > 0:
        # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„å¼‚å¸¸å€¼å¤„ç†åˆ—
        default_outlier_cols = st.session_state.get('outlier_cols', [])
        outlier_cols = st.multiselect(
            "é€‰æ‹©è¦å¤„ç†å¼‚å¸¸å€¼çš„åˆ—", 
            numeric_cols,
            default=default_outlier_cols
        )
        # ä¿å­˜é€‰æ‹©åˆ°session_state
        st.session_state['outlier_cols'] = outlier_cols
        
        if outlier_cols:
            # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•
            default_outlier_method = st.session_state.get('outlier_method', "3sigma")
            outlier_method = st.selectbox(
                "é€‰æ‹©å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•", 
                ["3sigma", "iqr"],
                index=["3sigma", "iqr"].index(default_outlier_method)
            )
            # ä¿å­˜é€‰æ‹©åˆ°session_state
            st.session_state['outlier_method'] = outlier_method
            
            if st.button("å¤„ç†å¼‚å¸¸å€¼"):
                df_clean = remove_outliers(df_clean, outlier_cols, outlier_method)
                st.success(f"å·²å¤„ç†å¼‚å¸¸å€¼ï¼Œå¤„ç†å‰æ•°æ®é‡: {len(df)}ï¼Œå¤„ç†åæ•°æ®é‡: {len(df_clean)}")
    
    # ç‰¹å¾é€‰æ‹©
    st.subheader("3. ç‰¹å¾å’Œç›®æ ‡å˜é‡é€‰æ‹©")
    numeric_cols = df_clean.select_dtypes(include='number').columns.tolist()
    if len(numeric_cols) == 0:
        st.warning("æ•°æ®ä¸­æ²¡æœ‰æ•°å€¼åˆ—ï¼Œæ— æ³•è¿›è¡Œæœºå™¨å­¦ä¹ é¢„æµ‹ï¼")
        target_col = None
        selected_features = []
    else:
        # ä½¿ç”¨target_col_widgetä½œä¸ºkeyï¼Œè€Œä¸æ˜¯target_col
        # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„ç›®æ ‡å˜é‡
        default_target_idx = 0
        if 'target_col_value' in st.session_state and st.session_state['target_col_value'] in numeric_cols:
            default_target_idx = numeric_cols.index(st.session_state['target_col_value'])
            
        target_col = st.selectbox(
            "é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆè¦é¢„æµ‹çš„åˆ—ï¼‰", 
            numeric_cols, 
            index=default_target_idx,
            key="target_col_widget"
        )
        # ä¿å­˜é€‰æ‹©å€¼åˆ°session_stateï¼Œè€Œä¸æ˜¯ç”¨widgetçš„key
        st.session_state['target_col_value'] = target_col
        
        if target_col:
            corr_target = df_clean[numeric_cols].corr()[target_col].abs().sort_values(ascending=False)
            st.write("ç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§æ’åºï¼š")
            st.dataframe(corr_target)
            recommended_features = [col for col in corr_target.index if col != target_col and corr_target[col] > 0.1]
            available_features = [col for col in numeric_cols if col != target_col]
            
            # ä¿®å¤è¿™é‡Œçš„é”™è¯¯ï¼Œç¡®ä¿é»˜è®¤å€¼æ˜¯åˆ—è¡¨
            default_features = []
            if recommended_features:
                default_features = recommended_features[:min(5, len(recommended_features))]
            elif available_features:
                default_features = available_features[:min(5, len(available_features))]
                
            # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„ç‰¹å¾å˜é‡
            if 'feature_cols_value' in st.session_state:
                saved_features = st.session_state['feature_cols_value']
                default_features = [f for f in saved_features if f in available_features]
                
            # ä½¿ç”¨feature_cols_widgetä½œä¸ºkeyï¼Œè€Œä¸æ˜¯feature_cols
            selected_features = st.multiselect(
                "é€‰æ‹©ç‰¹å¾å˜é‡ï¼ˆä¼˜å…ˆé€‰æ‹©é«˜ç›¸å…³æ€§ç‰¹å¾ï¼‰", 
                available_features, 
                default=default_features,
                key="feature_cols_widget"
            )
            # ä¿å­˜é€‰æ‹©å€¼åˆ°session_stateï¼Œè€Œä¸æ˜¯ç”¨widgetçš„key
            st.session_state['feature_cols_value'] = selected_features
        else:
            selected_features = []
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®å’Œé€‰æ‹©åˆ°session_state
    st.session_state['df_clean'] = df_clean
    st.session_state['target_col'] = target_col
    st.session_state['selected_features'] = selected_features
    
    return df_clean, target_col, selected_features

# ========== æ¨¡å‹é¢„æµ‹æ¨¡å— ==========
def render_model_prediction():
    """æ¸²æŸ“æ¨¡å‹é¢„æµ‹ç•Œé¢"""
    st.header("æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹")
    
    if 'df_clean' not in st.session_state or 'target_col' not in st.session_state or 'selected_features' not in st.session_state:
        st.info("è¯·å…ˆåœ¨'ç‰¹å¾å·¥ç¨‹'æ ‡ç­¾é¡µå®Œæˆæ•°æ®å¤„ç†")
        return
    
    df_clean = st.session_state['df_clean']
    target_col = st.session_state['target_col']
    selected_features = st.session_state['selected_features']
    
    if not target_col or not selected_features:
        st.info("è¯·å…ˆåœ¨'ç‰¹å¾å·¥ç¨‹'æ ‡ç­¾é¡µé€‰æ‹©ç›®æ ‡å˜é‡å’Œç‰¹å¾å˜é‡")
        return
    
    # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
    X = df_clean[selected_features].copy()
    y = df_clean[target_col].copy()
    
    # ç‰¹å¾ç¼©æ”¾
    if 'scaler' not in st.session_state:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        st.session_state['scaler'] = scaler
        st.session_state['X_scaled'] = X_scaled
    else:
        scaler = st.session_state['scaler']
        X_scaled = st.session_state.get('X_scaled', scaler.transform(X))
    
    # ç¡®å®šé—®é¢˜ç±»å‹
    if 'problem_type' not in st.session_state:
        if y.dtype in ['int64', 'float64'] and len(y.unique()) > 10:
            problem_type = "å›å½’"
            models = get_regression_models()
        else:
            problem_type = "åˆ†ç±»"
            # ç¡®ä¿åˆ†ç±»æ ‡ç­¾ä»0å¼€å§‹ï¼ˆå¯¹XGBoostç­‰æ¨¡å‹å¾ˆé‡è¦ï¼‰
            if y.min() != 0 and XGBClassifier is not None:
                st.info(f"æ³¨æ„ï¼šåˆ†ç±»æ ‡ç­¾å·²ä» {y.min()} è°ƒæ•´ä¸ºä»0å¼€å§‹ï¼Œä»¥å…¼å®¹XGBoostç­‰æ¨¡å‹")
                y = y - y.min()
            models = get_classification_models()
        
        st.session_state['problem_type'] = problem_type
        st.session_state['models'] = models
        st.session_state['y'] = y
    else:
        problem_type = st.session_state['problem_type']
        models = st.session_state['models']
        y = st.session_state.get('y', y)
    
    st.write(f"æ£€æµ‹åˆ°çš„é—®é¢˜ç±»å‹: {problem_type}")
    
    # æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒ
    model_names = list(models.keys())
    
    # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„æ¨¡å‹
    default_models = st.session_state.get('selected_models', model_names[:2])
    selected_models = st.multiselect("é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ï¼ˆå¯å¤šé€‰ï¼‰", model_names, default=default_models)
    st.session_state['selected_models'] = selected_models
    
    # ä»session_stateæ¢å¤ä¹‹å‰é€‰æ‹©çš„æµ‹è¯•é›†æ¯”ä¾‹
    test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, st.session_state.get('test_size', 0.2), 0.05)
    st.session_state['test_size'] = test_size
    
    # æ·»åŠ å‚æ•°ä¼˜åŒ–é€‰é¡¹ï¼Œä»session_stateæ¢å¤ä¹‹å‰çš„é€‰æ‹©
    enable_param_search = st.checkbox("å¯ç”¨å‚æ•°ä¼˜åŒ–", value=st.session_state.get('enable_param_search', False), 
                                     help="ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–éšæœºæœç´¢å¯»æ‰¾æœ€ä½³å‚æ•°")
    st.session_state['enable_param_search'] = enable_param_search
    
    if enable_param_search:
        search_method = st.radio("å‚æ•°æœç´¢æ–¹æ³•", ["ç½‘æ ¼æœç´¢(GridSearchCV)", "éšæœºæœç´¢(RandomizedSearchCV)"], 
                               index=0 if st.session_state.get('search_method', "") == "ç½‘æ ¼æœç´¢(GridSearchCV)" else 1)
        st.session_state['search_method'] = search_method
        
        n_iter = 10
        if search_method == "éšæœºæœç´¢(RandomizedSearchCV)":
            n_iter = st.slider("éšæœºæœç´¢è¿­ä»£æ¬¡æ•°", 5, 50, st.session_state.get('n_iter', 10))
            st.session_state['n_iter'] = n_iter
            
        cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 2, 10, st.session_state.get('cv_folds', 3))
        st.session_state['cv_folds'] = cv_folds
    
    # æ˜¾ç¤ºä¹‹å‰çš„è®­ç»ƒç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    if 'results' in st.session_state and st.session_state['results']:
        st.write("## ä¹‹å‰çš„è®­ç»ƒç»“æœï¼š")
        
        # åˆ›å»ºä¸åŒ…å«æ¨¡å‹å¯¹è±¡çš„ç»“æœå‰¯æœ¬ç”¨äºæ˜¾ç¤º
        display_results = []
        for result in st.session_state['results']:
            display_result = {k: v for k, v in result.items() if k != 'model' and k != 'model_name'}
            display_results.append(display_result)
            
        st.dataframe(pd.DataFrame(display_results))
        
        if 'best_model_name' in st.session_state and st.session_state['best_model_name']:
            st.success(f"æ¨èæœ€ä½³æ¨¡å‹ï¼š{st.session_state['best_model_name']}")
            if 'best_params' in st.session_state and st.session_state['best_params'] != "é»˜è®¤å‚æ•°":
                st.write("æœ€ä½³å‚æ•°ï¼š")
                st.json(st.session_state['best_params'])
    
    if st.button("å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹"):
        with st.spinner("æ­£åœ¨è®­ç»ƒæ‰€æœ‰æ¨¡å‹..."):
            # å¦‚æœä¹‹å‰æ²¡æœ‰æ‹†åˆ†æ•°æ®ï¼Œæˆ–è€…æµ‹è¯•é›†æ¯”ä¾‹æ”¹å˜äº†ï¼Œé‡æ–°æ‹†åˆ†æ•°æ®
            if ('X_train' not in st.session_state or 'X_test' not in st.session_state or 
                'y_train' not in st.session_state or 'y_test' not in st.session_state or
                abs(st.session_state.get('last_test_size', 0) - test_size) > 0.001):
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=test_size, random_state=42
                )
                
                # ä¿å­˜è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ°session_state
                st.session_state['X_train'] = X_train
                st.session_state['X_test'] = X_test
                st.session_state['y_train'] = y_train
                st.session_state['y_test'] = y_test
                st.session_state['last_test_size'] = test_size
            else:
                X_train = st.session_state['X_train']
                X_test = st.session_state['X_test']
                y_train = st.session_state['y_train']
                y_test = st.session_state['y_test']
            
            results = []
            best_score = None
            best_model = None
            best_model_name = None
            best_params = None
            
            # å­˜å‚¨æ‰€æœ‰è®­ç»ƒçš„æ¨¡å‹
            trained_models = {}
            
            for name in selected_models:
                base_model = models[name]
                try:
                    if enable_param_search:
                        # æ ¹æ®æ¨¡å‹ç±»å‹è·å–å‚æ•°ç½‘æ ¼
                        param_grid = get_param_grid(name, problem_type)
                        
                        if param_grid:  # å¦‚æœæœ‰å¯ç”¨çš„å‚æ•°ç½‘æ ¼
                            if search_method == "ç½‘æ ¼æœç´¢(GridSearchCV)":
                                search = GridSearchCV(
                                    estimator=base_model,
                                    param_grid=param_grid,
                                    cv=cv_folds,
                                    scoring='r2' if problem_type == "å›å½’" else 'accuracy',
                                    n_jobs=-1 if hasattr(base_model, 'n_jobs') else None
                                )
                            else:  # éšæœºæœç´¢
                                search = RandomizedSearchCV(
                                    estimator=base_model,
                                    param_distributions=param_grid,
                                    n_iter=n_iter,
                                    cv=cv_folds,
                                    scoring='r2' if problem_type == "å›å½’" else 'accuracy',
                                    n_jobs=-1 if hasattr(base_model, 'n_jobs') else None,
                                    random_state=42
                                )
                            
                            # æ‰§è¡Œå‚æ•°æœç´¢
                            with st.spinner(f"æ­£åœ¨ä¸º {name} ä¼˜åŒ–å‚æ•°..."):
                                search.fit(X_train, y_train)
                            
                            # è·å–æœ€ä½³æ¨¡å‹å’Œå‚æ•°
                            model = search.best_estimator_
                            current_params = search.best_params_
                            st.success(f"{name} æœ€ä½³å‚æ•°: {current_params}")
                        else:
                            st.info(f"{name} æ²¡æœ‰å¯ç”¨çš„å‚æ•°ç½‘æ ¼ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                            model = base_model
                            model.fit(X_train, y_train)
                            current_params = "é»˜è®¤å‚æ•°"
                    else:
                        model = base_model
                        model.fit(X_train, y_train)
                        current_params = "é»˜è®¤å‚æ•°"
                    
                    y_pred = model.predict(X_test)
                    
                    # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
                    trained_models[name] = model
                    
                    if problem_type == "å›å½’":
                        r2 = r2_score(y_test, y_pred)
                        mse = mean_squared_error(y_test, y_pred)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_test, y_pred)
                        # ä¿®å¤MAPEè®¡ç®—ï¼Œç¡®ä¿ä½¿ç”¨æ•°å€¼è€Œéåˆ—è¡¨
                        y_test_values = np.array(y_test)
                        mape = np.mean(np.abs((y_test_values - y_pred) / (y_test_values + 1e-8))) * 100
                        result = {
                            "æ¨¡å‹": name,
                            "RÂ²åˆ†æ•°": f"{r2:.4f}",
                            "å‡æ–¹è¯¯å·®(MSE)": f"{mse:.4f}",
                            "å‡æ–¹æ ¹è¯¯å·®(RMSE)": f"{rmse:.4f}",
                            "å¹³å‡ç»å¯¹è¯¯å·®(MAE)": f"{mae:.4f}",
                            "å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®(MAPE%)": f"{mape:.2f}",
                            "å‚æ•°": str(current_params),
                            "model_name": name,
                            "model": model
                        }
                        results.append(result)
                        if best_score is None or r2 > best_score:
                            best_score = r2
                            best_model = model
                            best_model_name = name
                            best_params = current_params
                    else:
                        acc = accuracy_score(y_test, y_pred)
                        f1 = f1_score(y_test, y_pred, average='weighted', zero_division='warn')
                        precision = precision_score(y_test, y_pred, average='weighted', zero_division='warn')
                        recall = recall_score(y_test, y_pred, average='weighted', zero_division='warn')
                        # AUCåªå¯¹äºŒåˆ†ç±»ä¸”æœ‰predict_probaæ”¯æŒçš„æ¨¡å‹æœ‰æ•ˆ
                        auc_score = None
                        if hasattr(model, 'predict_proba') and len(np.unique(y_test)) == 2:
                            try:
                                auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
                            except Exception:
                                auc_score = None
                        result = {
                            "æ¨¡å‹": name,
                            "å‡†ç¡®ç‡": f"{acc:.4f}",
                            "F1åˆ†æ•°": f"{f1:.4f}",
                            "ç²¾ç¡®ç‡": f"{precision:.4f}",
                            "å¬å›ç‡": f"{recall:.4f}",
                            "AUC": f"{auc_score:.4f}" if auc_score is not None else "-",
                            "å‚æ•°": str(current_params),
                            "model_name": name,
                            "model": model
                        }
                        results.append(result)
                        if best_score is None or acc > best_score:
                            best_score = acc
                            best_model = model
                            best_model_name = name
                            best_params = current_params
                except Exception as e:
                    results.append({"æ¨¡å‹": name, "é”™è¯¯": str(e)})
            
            # ä¿å­˜ç»“æœåˆ°session_state
            st.session_state['results'] = results
            st.session_state['best_score'] = best_score
            st.session_state['best_model'] = best_model
            st.session_state['best_model_name'] = best_model_name
            st.session_state['best_params'] = best_params
            st.session_state['trained_models'] = trained_models
            
            # æ˜¾ç¤ºç»“æœè¡¨æ ¼ï¼ˆä¸åŒ…å«æ¨¡å‹å¯¹è±¡ï¼‰
            display_results = []
            for result in results:
                display_result = {k: v for k, v in result.items() if k != 'model' and k != 'model_name'}
                display_results.append(display_result)
            
            st.write("## å„æ¨¡å‹è¡¨ç°å¯¹æ¯”ï¼š")
            st.dataframe(pd.DataFrame(display_results))
            
            if best_model is not None:
                st.success(f"æ¨èæœ€ä½³æ¨¡å‹ï¼š{best_model_name}")
                if best_params != "é»˜è®¤å‚æ•°":
                    st.write("æœ€ä½³å‚æ•°ï¼š")
                    st.json(best_params)
                
                # æ·»åŠ ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
                if hasattr(best_model, 'feature_importances_'):
                    st.subheader("ç‰¹å¾é‡è¦æ€§")
                    importances = best_model.feature_importances_
                    indices = np.argsort(importances)[::-1]
                    feature_names = np.array(selected_features)[indices]
                    importances = importances[indices]
                    
                    fig = px.bar(
                        x=importances, 
                        y=feature_names,
                        orientation='h',
                        labels={'x': 'é‡è¦æ€§', 'y': 'ç‰¹å¾'},
                        title='ç‰¹å¾é‡è¦æ€§æ’åº'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°session_state
                st.session_state['model'] = best_model
                st.session_state['model_name'] = best_model_name
                st.session_state['y_pred'] = best_model.predict(X_test)

def get_regression_models():
    """è·å–å›å½’æ¨¡å‹å­—å…¸"""
    models = {
        "çº¿æ€§å›å½’": LinearRegression(),
        "å²­å›å½’": Ridge(),
        "Lassoå›å½’": Lasso(),
        "å†³ç­–æ ‘å›å½’": DecisionTreeRegressor(),
        "éšæœºæ£®æ—å›å½’": RandomForestRegressor(n_estimators=100, random_state=42),
        "æ”¯æŒå‘é‡å›å½’": SVR(kernel='rbf')
    }
    if XGBRegressor is not None:
        models["XGBoostå›å½’"] = XGBRegressor()
    
    # åœ¨å‡½æ•°å†…éƒ¨å°è¯•å¯¼å…¥LightGBM
    try:
        from lightgbm import LGBMRegressor
        models["LightGBMå›å½’"] = LGBMRegressor()
    except (ImportError, Exception) as e:
        st.write(f"LightGBMå›å½’æ¨¡å‹ä¸å¯ç”¨: {e}")
    
    return models

def get_classification_models():
    """è·å–åˆ†ç±»æ¨¡å‹å­—å…¸"""
    models = {
        "é€»è¾‘å›å½’": LogisticRegression(random_state=42),
        "å†³ç­–æ ‘åˆ†ç±»": DecisionTreeClassifier(),
        "éšæœºæ£®æ—åˆ†ç±»": RandomForestClassifier(n_estimators=100, random_state=42),
        "æ”¯æŒå‘é‡åˆ†ç±»": SVC(kernel='rbf', probability=True, random_state=42),
        "Kè¿‘é‚»åˆ†ç±»": KNeighborsClassifier(),
        "æœ´ç´ è´å¶æ–¯": GaussianNB()
    }
    if XGBClassifier is not None:
        models["XGBooståˆ†ç±»"] = XGBClassifier()
    
    # åœ¨å‡½æ•°å†…éƒ¨å°è¯•å¯¼å…¥LightGBM
    try:
        from lightgbm import LGBMClassifier
        models["LightGBMåˆ†ç±»"] = LGBMClassifier()
    except (ImportError, Exception) as e:
        st.write(f"LightGBMåˆ†ç±»æ¨¡å‹ä¸å¯ç”¨: {e}")
    
    return models

def get_param_grid(model_name, problem_type):
    """æ ¹æ®æ¨¡å‹åç§°å’Œé—®é¢˜ç±»å‹è·å–å‚æ•°ç½‘æ ¼"""
    if "çº¿æ€§å›å½’" in model_name:
        return {
            'fit_intercept': [True, False],
            'normalize': [True, False]
        }
    elif "å²­å›å½’" in model_name or "Lasso" in model_name:
        return {
            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],
            'fit_intercept': [True, False]
        }
    elif "å†³ç­–æ ‘" in model_name:
        return {
            'max_depth': [None, 5, 10, 15, 20],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
    elif "éšæœºæ£®æ—" in model_name:
        return {
            'n_estimators': [50, 100, 200],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
    elif "æ”¯æŒå‘é‡" in model_name:
        return {
            'C': [0.1, 1, 10, 100],
            'gamma': ['scale', 'auto', 0.1, 1]
        }
    elif "Kè¿‘é‚»" in model_name:
        return {
            'n_neighbors': [3, 5, 7, 9, 11],
            'weights': ['uniform', 'distance'],
            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']
        }
    elif "é€»è¾‘å›å½’" in model_name:
        return {
            'C': [0.001, 0.01, 0.1, 1, 10, 100],
            'solver': ['liblinear', 'lbfgs'],
            'max_iter': [100, 200, 500]
        }
    elif "æœ´ç´ è´å¶æ–¯" in model_name:
        return {
            'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]
        }
    elif "XGBoost" in model_name:
        if problem_type == "å›å½’":
            return {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0]
            }
        else:
            return {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0]
            }
    elif "LightGBM" in model_name:
        if problem_type == "å›å½’":
            return {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'num_leaves': [31, 50, 100],
                'subsample': [0.8, 0.9, 1.0]
            }
        else:
            return {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'num_leaves': [31, 50, 100],
                'subsample': [0.8, 0.9, 1.0]
            }
    return None  # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰çš„å‚æ•°ç½‘æ ¼ï¼Œè¿”å›None

# ========== æ¨¡å‹è¯„ä¼°æ¨¡å— ==========
def render_model_evaluation():
    """æ¸²æŸ“æ¨¡å‹è¯„ä¼°ç•Œé¢"""
    st.header("æ¨¡å‹è¯„ä¼°ä¸é¢„æµ‹")
    
    if 'model' not in st.session_state:
        st.info("è¯·å…ˆåœ¨'æ¨¡å‹é¢„æµ‹'æ ‡ç­¾é¡µä¸­è®­ç»ƒæ¨¡å‹ã€‚")
        return
    
    # æ·»åŠ æ¨¡å‹é€‰æ‹©åŠŸèƒ½
    st.subheader("é€‰æ‹©è¯„ä¼°æ¨¡å‹")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¾›é€‰æ‹©
    trained_models = {}
    if 'trained_models' in st.session_state:
        trained_models = st.session_state['trained_models']
    elif 'results' in st.session_state and st.session_state['results']:
        for result in st.session_state['results']:
            if 'model_name' in result and 'model' in result:
                model_name = result['model_name']
                trained_models[model_name] = result['model']
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å­˜å‚¨çš„å¤šä¸ªæ¨¡å‹ï¼Œä½¿ç”¨å½“å‰æœ€ä½³æ¨¡å‹
    if not trained_models and 'model' in st.session_state:
        model_name = st.session_state.get('model_name', 'å½“å‰æœ€ä½³æ¨¡å‹')
        trained_models[model_name] = st.session_state['model']
    
    # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œæ˜¾ç¤ºé€‰æ‹©æ¡†
    if len(trained_models) > 1:
        selected_model_name = st.selectbox(
            "é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹", 
            list(trained_models.keys()),
            index=list(trained_models.keys()).index(st.session_state.get('model_name', list(trained_models.keys())[0])) if st.session_state.get('model_name') in trained_models else 0
        )
        
        # æ›´æ–°å½“å‰é€‰æ‹©çš„æ¨¡å‹
        if selected_model_name != st.session_state.get('model_name'):
            st.session_state['model'] = trained_models[selected_model_name]
            st.session_state['model_name'] = selected_model_name
            
            # æ›´æ–°é¢„æµ‹ç»“æœ
            if 'X_test' in st.session_state:
                st.session_state['y_pred'] = st.session_state['model'].predict(st.session_state['X_test'])
    else:
        selected_model_name = st.session_state.get('model_name', 'å½“å‰æ¨¡å‹')
        st.write(f"å½“å‰ä½¿ç”¨æ¨¡å‹: **{selected_model_name}**")
    
    # æ˜¾ç¤ºæ¨¡å‹å‚æ•°
    if selected_model_name:
        st.subheader("æ¨¡å‹å‚æ•°")
        model = st.session_state['model']
        
        # å°è¯•è·å–æ¨¡å‹å‚æ•°
        try:
            # é¦–å…ˆå°è¯•ä»resultsä¸­è·å–å‚æ•°
            model_params = None
            if 'results' in st.session_state:
                for result in st.session_state['results']:
                    if result.get('æ¨¡å‹') == selected_model_name and 'å‚æ•°' in result:
                        model_params = result['å‚æ•°']
                        break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»æ¨¡å‹å¯¹è±¡è·å–å‚æ•°
            if model_params is None:
                if hasattr(model, 'get_params'):
                    model_params = model.get_params()
                else:
                    model_params = "æ— æ³•è·å–æ¨¡å‹å‚æ•°"
            
            # æ˜¾ç¤ºå‚æ•°
            if isinstance(model_params, dict):
                st.json(model_params)
            else:
                st.write(model_params)
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹å‚æ•°æ—¶å‡ºé”™: {e}")
    
    st.subheader("1. æ¨¡å‹æ€§èƒ½è¯„ä¼°")
    
    # æ˜¾ç¤ºæµ‹è¯•é›†é¢„æµ‹ç»“æœ
    if st.session_state['problem_type'] == "å›å½’":
        render_regression_evaluation()
    else:
        render_classification_evaluation()
    
    # æ–°æ•°æ®é¢„æµ‹ç•Œé¢
    st.subheader("2. æ–°æ•°æ®é¢„æµ‹")
    render_prediction_interface()

def render_regression_evaluation():
    """æ¸²æŸ“å›å½’é—®é¢˜è¯„ä¼°"""
    # å®é™…å€¼vsé¢„æµ‹å€¼å›¾
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        y=st.session_state['y_test'], 
        mode='markers', 
        name='å®é™…å€¼',
        marker=dict(color='blue')
    ))
    fig.add_trace(go.Scatter(
        y=st.session_state['y_pred'], 
        mode='markers', 
        name='é¢„æµ‹å€¼',
        marker=dict(color='red')
    ))
    fig.update_layout(title="å®é™…å€¼ vs é¢„æµ‹å€¼", xaxis_title="æ ·æœ¬", yaxis_title="å€¼")
    st.plotly_chart(fig, use_container_width=True)
    
    # æ®‹å·®å›¾
    residuals = st.session_state['y_test'] - st.session_state['y_pred']
    fig_residual = px.scatter(
        x=st.session_state['y_pred'], 
        y=residuals, 
        title="æ®‹å·®å›¾", 
        labels={'x': 'é¢„æµ‹å€¼', 'y': 'æ®‹å·®'}
    )
    fig_residual.add_hline(y=0, line_dash="dash", line_color="red")
    st.plotly_chart(fig_residual, use_container_width=True)

def render_classification_evaluation():
    """æ¸²æŸ“åˆ†ç±»é—®é¢˜è¯„ä¼°"""
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(st.session_state['y_test'], st.session_state['y_pred'])
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
    ax.set_title('æ··æ·†çŸ©é˜µ')
    ax.set_xlabel('é¢„æµ‹æ ‡ç­¾')
    ax.set_ylabel('çœŸå®æ ‡ç­¾')
    st.pyplot(fig)
    
    # æ·»åŠ åˆ†ç±»æŠ¥å‘Šå¯è§†åŒ–
    report = classification_report(
        st.session_state['y_test'], 
        st.session_state['y_pred'], 
        output_dict=True
    )
    
    # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿å¯è§†åŒ–
    report_df = pd.DataFrame(report).T
    report_df = report_df.drop('support', axis=1)  # ç§»é™¤supportåˆ—ä»¥ä¾¿æ›´å¥½åœ°å¯è§†åŒ–
    
    # ä½¿ç”¨çƒ­åŠ›å›¾æ˜¾ç¤ºåˆ†ç±»æŠ¥å‘Š
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.heatmap(report_df, annot=True, cmap='YlGnBu', ax=ax, fmt='.2f')
    ax.set_title('åˆ†ç±»æŠ¥å‘Š')
    st.pyplot(fig)
    
    # å¦‚æœæ¨¡å‹æ”¯æŒé¢„æµ‹æ¦‚ç‡ï¼Œæ·»åŠ ROCæ›²çº¿
    if (hasattr(st.session_state['model'], 'predict_proba') and 
        len(np.unique(st.session_state['y_test'])) == 2):
        y_prob = st.session_state['model'].predict_proba(st.session_state['X_test'])[:, 1]
        fpr, tpr, _ = roc_curve(st.session_state['y_test'], y_prob)
        roc_auc = auc(fpr, tpr)
        
        fig = px.line(
            x=fpr, y=tpr,
            labels={'x': 'å‡æ­£ä¾‹ç‡', 'y': 'çœŸæ­£ä¾‹ç‡'},
            title=f'ROCæ›²çº¿ (AUC = {roc_auc:.3f})'
        )
        fig.add_shape(
            type='line', line=dict(dash='dash'),
            x0=0, x1=1, y0=0, y1=1
        )
        st.plotly_chart(fig, use_container_width=True)

def render_prediction_interface():
    """æ¸²æŸ“é¢„æµ‹ç•Œé¢"""
    # åˆ›å»ºé¢„æµ‹è¾“å…¥è¡¨å•
    st.write("è¾“å…¥æ–°æ•°æ®è¿›è¡Œé¢„æµ‹ï¼š")
    
    input_data = {}
    df_clean = st.session_state.get('df_clean')
    selected_features = st.session_state.get('selected_features', [])
    
    if df_clean is not None and selected_features:
        for feature in selected_features:
            # è·å–è¯¥ç‰¹å¾çš„æ•°æ®èŒƒå›´ç”¨äºè®¾ç½®é»˜è®¤å€¼
            feature_data = df_clean[feature]
            default_value = float(feature_data.mean())
            min_val = float(feature_data.min())
            max_val = float(feature_data.max())
            
            # è®¡ç®—æ­¥é•¿ï¼Œç¡®ä¿æ˜¯æµ®ç‚¹æ•°
            diff = max_val - min_val
            step_val = float(diff / 100.0) if diff > 0 else 0.01
            
            input_data[feature] = st.number_input(
                f"{feature}",
                min_value=min_val,
                max_value=max_val,
                value=default_value,
                step=step_val
            )
        
        if st.button("è¿›è¡Œé¢„æµ‹"):
            make_prediction(input_data)

def make_prediction(input_data: dict):
    """è¿›è¡Œé¢„æµ‹"""
    try:
        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_df = pd.DataFrame([input_data])
        input_scaled = st.session_state['scaler'].transform(input_df)
        
        # é¢„æµ‹
        prediction = st.session_state['model'].predict(input_scaled)
        
        st.success(f"é¢„æµ‹ç»“æœ: {prediction[0]:.4f}")
        
        # å¦‚æœæ˜¯åˆ†ç±»é—®é¢˜ï¼Œæ˜¾ç¤ºæ¦‚ç‡
        if (st.session_state['problem_type'] == "åˆ†ç±»" and 
            hasattr(st.session_state['model'], 'predict_proba')):
            probabilities = st.session_state['model'].predict_proba(input_scaled)
            st.write("é¢„æµ‹æ¦‚ç‡:")
            for i, prob in enumerate(probabilities[0]):
                st.write(f"ç±»åˆ« {i}: {prob:.4f}")
    except Exception as e:
        st.error(f"é¢„æµ‹æ—¶å‡ºé”™: {e}")

# ========== åº”ç”¨ä¸»æµç¨‹ ==========
def main():
    st.set_page_config(
        page_title=APP_CONFIG['page_title'],
        page_icon=APP_CONFIG['page_icon'],
        layout="wide",
        initial_sidebar_state="expanded"
    )
    st.title("æ•°æ®å¯è§†åŒ–ä¸æœºå™¨å­¦ä¹ é¢„æµ‹åˆ†æ")
    
    # åˆå§‹åŒ–session_stateä»¥å­˜å‚¨å½“å‰æ ‡ç­¾é¡µ
    if 'current_tab' not in st.session_state:
        st.session_state['current_tab'] = 0
    
    # ä¾§è¾¹æ ï¼šæ•°æ®åŠ è½½
    DATA_DIR = st.sidebar.text_input("æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„", value=DEFAULT_PATHS['data_directory'])
    if is_valid_directory(DATA_DIR):
        file_list = get_csv_files(DATA_DIR)
    else:
        file_list = []
    
    selected_file = st.sidebar.selectbox("é€‰æ‹©æ–‡ä»¶", file_list, key="file_selector")
    
    if selected_file:
        df = load_data(DATA_DIR, selected_file)
        if df is None:
            st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ï¼")
            return
        
        # åˆå§‹åŒ–session_state
        if 'df' not in st.session_state:
            st.session_state['df'] = df
        
        # åˆ›å»ºæ ‡ç­¾é¡µï¼Œä½¿ç”¨radioä»£æ›¿tabsä»¥ä¾¿æ›´å¥½åœ°ä¿æŒçŠ¶æ€
        tab_options = ["ğŸ“Š æ•°æ®å¯è§†åŒ–", "ğŸ› ï¸ ç‰¹å¾å·¥ç¨‹", "ğŸ¤– æ¨¡å‹é¢„æµ‹", "ğŸ“ˆ æ¨¡å‹è¯„ä¼°"]
        current_tab = st.radio("é€‰æ‹©åŠŸèƒ½", tab_options, index=int(st.session_state['current_tab']), horizontal=True)
        
        # æ›´æ–°å½“å‰æ ‡ç­¾é¡µç´¢å¼•
        st.session_state['current_tab'] = tab_options.index(current_tab)
        
        # æ ¹æ®é€‰æ‹©çš„æ ‡ç­¾é¡µæ˜¾ç¤ºç›¸åº”å†…å®¹
        if current_tab == "ğŸ“Š æ•°æ®å¯è§†åŒ–":
            render_visualization(df)
        elif current_tab == "ğŸ› ï¸ ç‰¹å¾å·¥ç¨‹":
            render_feature_engineering(df)
        elif current_tab == "ğŸ¤– æ¨¡å‹é¢„æµ‹":
            render_model_prediction()
        elif current_tab == "ğŸ“ˆ æ¨¡å‹è¯„ä¼°":
            render_model_evaluation()
    
    else:
        st.warning(f"æ–‡ä»¶å¤¹ '{DATA_DIR}' ä¸å­˜åœ¨æˆ–æ²¡æœ‰csvæ–‡ä»¶ï¼")

if __name__ == "__main__":
    main()
